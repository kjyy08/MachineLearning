{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNnzmZVh7uF9tUZRLXs++ca"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import os\n","from tensorflow.keras.layers import (Dense, BatchNormalization)\n","from tensorflow import keras\n","\n","file_path = \"./Dataset\"\n","\n","# 경로 내 모든 파일을 딕셔너리 형태로 읽음\n","def get_csv(file_path):\n","  tmp = dict()\n","  for file in os.listdir(file_path): # os.listdir(file_path) : 파일 list를 가지고 옴\n","    file_name = file[:-4] # .csv 확장자를 제외한 파일 이름 추출\n","    tmp[file_name] = pd.read_csv(file_path + \"/\" + file) # 파일 경로에 해당하는 csv파일을 가지고 옴\n","\n","  return tmp\n","\n","# 데이터 프레임을 기준에 맞게 하나로 합침\n","def merge(dict_data):\n","  test_Data = pd.merge(dict_data[\"gender_submission\"], dict_data[\"test\"], how=\"outer\", on=\"PassengerId\") # 두 데이터 프레임을 id를 기준으로 해서 하나로 합침\n","  mergeData = pd.concat([dict_data[\"train\"], test_Data]) # 두 데이터 프레임을 행 기준으로 합침\n","  mergeData.reset_index(drop=True, inplace=True) # drop = 인덱스로 설정한 열을 데이터 프레임에서 삭제, inplace = 원본 객체 변경 여부\n","\n","  return mergeData\n","\n","from copy import copy\n","# list에 해당하는 열 제거\n","def remove_col(remove_list):\n","  result = copy(merge_dataSet) # 원본 복사\n","\n","  result.set_index(\"PassengerId\", inplace=True) # 승객 번호를 index로 지정\n","\n","  for col in remove_list:\n","    del(result[col])\n","\n","  return result\n","\n","# 폴더 내 csv 파일 읽어옴\n","dataSet = get_csv(file_path)\n","# csv 파일들을 하나로 합침\n","merge_dataSet = merge(dataSet)\n","# 학습에 필요없는 값들 제거\n","remove_list = [\"Name\", \"Ticket\", \"Cabin\", \"Embarked\"]\n","df_data = remove_col(remove_list)\n","# 결측 값 제거\n","df_data.dropna(inplace=True)\n","# 학습을 위해 문자를 정수로 변환\n","df_data[\"Sex\"] = np.where(df_data[\"Sex\"].to_numpy() == \"male\", 0, 1)\n","\n","# Min-Max Scaling, 최소 값은 0, 최대 값을 1로 모든 데이터를 0 ~ 1 범위 안에 들어가도록 조절함\n","age_min, age_max = np.min(df_data[\"Age\"]), np.max(df_data[\"Age\"])\n","fare_min, fare_max = np.min(df_data[\"Fare\"]), np.max(df_data[\"Fare\"])\n","df_data[\"Age\"] = (df_data[\"Age\"] - age_min) / (age_max - age_min)\n","df_data[\"Fare\"] = (df_data[\"Fare\"] - age_min) / (age_max - age_min)\n","\n","# test데이터를 200개 그 외의 값들은 모두 train으로 사용\n","y_test, y_train = df_data[\"Survived\"][:200].to_numpy(), df_data[\"Survived\"][200:].to_numpy()\n","del(df_data[\"Survived\"])\n","x_test, x_train = df_data[:200].values, df_data[200:].values\n","x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n","print(\"x_train: \", len(x_train), \"  x_test: \", len(x_test))\n","# 학습률 설정\n","learning_rate = 0.01\n","\n","# 순차적 구조 모델 생성\n","model = keras.Sequential()\n","# 배치 정규화, 각 층의 입력을 정규화하여 학습 속도와 안정성을 증가시킴\n","model.add(BatchNormalization())\n","# 모델에 레이어 층 생성\n","model.add(Dense(32, input_dim=7, activation = \"relu\"))\n","model.add(Dense(16, activation = \"relu\"))\n","model.add(Dense(4, activation = \"relu\"))\n","model.add(Dense(1, activation = \"sigmoid\"))\n","\n","# 모델 학습 전 최적화 함수, 손실 함수, 평가 지표 등 설정\n","optimizer = keras.optimizers.Adam(learning_rate)\n","model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n","\n","# 학습 진행\n","model.fit(x_train, y_train, batch_size=64, epochs=100)\n","\n","# 평가\n","prediction = model.predict(x_test).reshape(x_test.shape[0])\n","prediction = tf.cast(prediction > 0.5, dtype=tf.float32)\n","accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, y_test), dtype=np.float32))\n","\n","# 정확도 출력\n","print(\"accuracy: \", accuracy.numpy())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TJlv8-pAYtRs","executionInfo":{"status":"ok","timestamp":1701667472632,"user_tz":-540,"elapsed":17896,"user":{"displayName":"김주엽","userId":"12669261044801974628"}},"outputId":"6b731e5e-e68c-4283-9e30-61cd79536f76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train:  845   x_test:  200\n","Epoch 1/100\n","14/14 [==============================] - 1s 3ms/step - loss: 0.5298 - binary_accuracy: 0.7917\n","Epoch 2/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3743 - binary_accuracy: 0.8615\n","Epoch 3/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3721 - binary_accuracy: 0.8615\n","Epoch 4/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3884 - binary_accuracy: 0.8402\n","Epoch 5/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3618 - binary_accuracy: 0.8556\n","Epoch 6/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.3366 - binary_accuracy: 0.8734\n","Epoch 7/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3405 - binary_accuracy: 0.8746\n","Epoch 8/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3417 - binary_accuracy: 0.8710\n","Epoch 9/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3338 - binary_accuracy: 0.8781\n","Epoch 10/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3301 - binary_accuracy: 0.8769\n","Epoch 11/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3272 - binary_accuracy: 0.8722\n","Epoch 12/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3264 - binary_accuracy: 0.8769\n","Epoch 13/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3213 - binary_accuracy: 0.8793\n","Epoch 14/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3297 - binary_accuracy: 0.8757\n","Epoch 15/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3243 - binary_accuracy: 0.8793\n","Epoch 16/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3313 - binary_accuracy: 0.8734\n","Epoch 17/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3407 - binary_accuracy: 0.8710\n","Epoch 18/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.3179 - binary_accuracy: 0.8746\n","Epoch 19/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.3305 - binary_accuracy: 0.8757\n","Epoch 20/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.3239 - binary_accuracy: 0.8698\n","Epoch 21/100\n","14/14 [==============================] - 0s 8ms/step - loss: 0.3326 - binary_accuracy: 0.8769\n","Epoch 22/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.3186 - binary_accuracy: 0.8781\n","Epoch 23/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.3145 - binary_accuracy: 0.8793\n","Epoch 24/100\n","14/14 [==============================] - 0s 8ms/step - loss: 0.3100 - binary_accuracy: 0.8710\n","Epoch 25/100\n","14/14 [==============================] - 0s 11ms/step - loss: 0.3160 - binary_accuracy: 0.8757\n","Epoch 26/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.3095 - binary_accuracy: 0.8805\n","Epoch 27/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.3087 - binary_accuracy: 0.8722\n","Epoch 28/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.3120 - binary_accuracy: 0.8722\n","Epoch 29/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.3187 - binary_accuracy: 0.8781\n","Epoch 30/100\n","14/14 [==============================] - 0s 9ms/step - loss: 0.3250 - binary_accuracy: 0.8686\n","Epoch 31/100\n","14/14 [==============================] - 0s 9ms/step - loss: 0.3086 - binary_accuracy: 0.8805\n","Epoch 32/100\n","14/14 [==============================] - 0s 8ms/step - loss: 0.3083 - binary_accuracy: 0.8805\n","Epoch 33/100\n","14/14 [==============================] - 0s 9ms/step - loss: 0.3201 - binary_accuracy: 0.8722\n","Epoch 34/100\n","14/14 [==============================] - 0s 8ms/step - loss: 0.3266 - binary_accuracy: 0.8722\n","Epoch 35/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.3214 - binary_accuracy: 0.8746\n","Epoch 36/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.3089 - binary_accuracy: 0.8757\n","Epoch 37/100\n","14/14 [==============================] - 0s 17ms/step - loss: 0.3117 - binary_accuracy: 0.8805\n","Epoch 38/100\n","14/14 [==============================] - 0s 13ms/step - loss: 0.3100 - binary_accuracy: 0.8686\n","Epoch 39/100\n","14/14 [==============================] - 0s 12ms/step - loss: 0.3184 - binary_accuracy: 0.8781\n","Epoch 40/100\n","14/14 [==============================] - 0s 11ms/step - loss: 0.3139 - binary_accuracy: 0.8769\n","Epoch 41/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.3111 - binary_accuracy: 0.8828\n","Epoch 42/100\n","14/14 [==============================] - 0s 10ms/step - loss: 0.3092 - binary_accuracy: 0.8757\n","Epoch 43/100\n","14/14 [==============================] - 0s 16ms/step - loss: 0.3072 - binary_accuracy: 0.8793\n","Epoch 44/100\n","14/14 [==============================] - 0s 19ms/step - loss: 0.3014 - binary_accuracy: 0.8793\n","Epoch 45/100\n","14/14 [==============================] - 0s 18ms/step - loss: 0.3005 - binary_accuracy: 0.8734\n","Epoch 46/100\n","14/14 [==============================] - 0s 17ms/step - loss: 0.3111 - binary_accuracy: 0.8793\n","Epoch 47/100\n","14/14 [==============================] - 0s 25ms/step - loss: 0.3155 - binary_accuracy: 0.8722\n","Epoch 48/100\n","14/14 [==============================] - 0s 14ms/step - loss: 0.3052 - binary_accuracy: 0.8805\n","Epoch 49/100\n","14/14 [==============================] - 0s 16ms/step - loss: 0.3011 - binary_accuracy: 0.8840\n","Epoch 50/100\n","14/14 [==============================] - 0s 13ms/step - loss: 0.3066 - binary_accuracy: 0.8769\n","Epoch 51/100\n","14/14 [==============================] - 0s 14ms/step - loss: 0.2973 - binary_accuracy: 0.8888\n","Epoch 52/100\n","14/14 [==============================] - 0s 11ms/step - loss: 0.3154 - binary_accuracy: 0.8710\n","Epoch 53/100\n","14/14 [==============================] - 0s 10ms/step - loss: 0.3033 - binary_accuracy: 0.8805\n","Epoch 54/100\n","14/14 [==============================] - 0s 9ms/step - loss: 0.3022 - binary_accuracy: 0.8805\n","Epoch 55/100\n","14/14 [==============================] - 0s 11ms/step - loss: 0.2968 - binary_accuracy: 0.8852\n","Epoch 56/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.3069 - binary_accuracy: 0.8757\n","Epoch 57/100\n","14/14 [==============================] - 0s 11ms/step - loss: 0.3047 - binary_accuracy: 0.8793\n","Epoch 58/100\n","14/14 [==============================] - 0s 14ms/step - loss: 0.3030 - binary_accuracy: 0.8793\n","Epoch 59/100\n","14/14 [==============================] - 0s 9ms/step - loss: 0.2921 - binary_accuracy: 0.8817\n","Epoch 60/100\n","14/14 [==============================] - 0s 11ms/step - loss: 0.3015 - binary_accuracy: 0.8817\n","Epoch 61/100\n","14/14 [==============================] - 0s 11ms/step - loss: 0.3004 - binary_accuracy: 0.8793\n","Epoch 62/100\n","14/14 [==============================] - 0s 23ms/step - loss: 0.2929 - binary_accuracy: 0.8864\n","Epoch 63/100\n","14/14 [==============================] - 0s 10ms/step - loss: 0.2958 - binary_accuracy: 0.8852\n","Epoch 64/100\n","14/14 [==============================] - 0s 13ms/step - loss: 0.2967 - binary_accuracy: 0.8805\n","Epoch 65/100\n","14/14 [==============================] - 0s 11ms/step - loss: 0.3079 - binary_accuracy: 0.8746\n","Epoch 66/100\n","14/14 [==============================] - 0s 9ms/step - loss: 0.3173 - binary_accuracy: 0.8793\n","Epoch 67/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.3056 - binary_accuracy: 0.8840\n","Epoch 68/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.3008 - binary_accuracy: 0.8805\n","Epoch 69/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.3042 - binary_accuracy: 0.8793\n","Epoch 70/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.3000 - binary_accuracy: 0.8769\n","Epoch 71/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.3018 - binary_accuracy: 0.8757\n","Epoch 72/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.3016 - binary_accuracy: 0.8817\n","Epoch 73/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.3019 - binary_accuracy: 0.8746\n","Epoch 74/100\n","14/14 [==============================] - 0s 9ms/step - loss: 0.3033 - binary_accuracy: 0.8840\n","Epoch 75/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.3017 - binary_accuracy: 0.8793\n","Epoch 76/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.2935 - binary_accuracy: 0.8805\n","Epoch 77/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.3069 - binary_accuracy: 0.8734\n","Epoch 78/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.3067 - binary_accuracy: 0.8793\n","Epoch 79/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.3086 - binary_accuracy: 0.8769\n","Epoch 80/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.2981 - binary_accuracy: 0.8781\n","Epoch 81/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.2888 - binary_accuracy: 0.8828\n","Epoch 82/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.2941 - binary_accuracy: 0.8805\n","Epoch 83/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2889 - binary_accuracy: 0.8864\n","Epoch 84/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2977 - binary_accuracy: 0.8840\n","Epoch 85/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2985 - binary_accuracy: 0.8828\n","Epoch 86/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2880 - binary_accuracy: 0.8852\n","Epoch 87/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3039 - binary_accuracy: 0.8781\n","Epoch 88/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2988 - binary_accuracy: 0.8769\n","Epoch 89/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3072 - binary_accuracy: 0.8746\n","Epoch 90/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2989 - binary_accuracy: 0.8769\n","Epoch 91/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3025 - binary_accuracy: 0.8746\n","Epoch 92/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3013 - binary_accuracy: 0.8781\n","Epoch 93/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2923 - binary_accuracy: 0.8828\n","Epoch 94/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2915 - binary_accuracy: 0.8793\n","Epoch 95/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2912 - binary_accuracy: 0.8769\n","Epoch 96/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.3060 - binary_accuracy: 0.8769\n","Epoch 97/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2993 - binary_accuracy: 0.8817\n","Epoch 98/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2959 - binary_accuracy: 0.8781\n","Epoch 99/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2921 - binary_accuracy: 0.8840\n","Epoch 100/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.2996 - binary_accuracy: 0.8828\n","7/7 [==============================] - 0s 2ms/step\n","accuracy:  0.82\n"]}]}]}