{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmiGDf7Ri96jMo535okVN9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"id":"R46Mo6m_xoHE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696496879139,"user_tz":-540,"elapsed":101529,"user":{"displayName":"김주엽","userId":"12669261044801974628"}},"outputId":"7c31c9b8-5cc7-4a1c-8037-e07e30b4373d"},"outputs":[{"output_type":"stream","name":"stdout","text":["step:  0 \n","Hypothesis:  [[1.9932920e-02]\n"," [8.4346964e-04]\n"," [9.8663233e-03]\n"," [6.2890700e-05]\n"," [1.7167047e-05]\n"," [3.0813921e-05]] \n","Correct (Y):  [[0.]\n"," [0.]\n"," [0.]\n"," [0.]\n"," [0.]\n"," [0.]] \n","Accuracy:  0.5 \n","Cost:  5.177511\n","---------------------------------\n","step:  1000 \n","Hypothesis:  [[0.2875091 ]\n"," [0.23048727]\n"," [0.8361527 ]\n"," [0.57134265]\n"," [0.73764765]\n"," [0.9439971 ]] \n","Correct (Y):  [[0.]\n"," [0.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]] \n","Accuracy:  0.8333333 \n","Cost:  0.555249\n","---------------------------------\n","step:  2000 \n","Hypothesis:  [[0.20889898]\n"," [0.21136756]\n"," [0.77412754]\n"," [0.599194  ]\n"," [0.7792864 ]\n"," [0.9509886 ]] \n","Correct (Y):  [[0.]\n"," [0.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]] \n","Accuracy:  0.8333333 \n","Cost:  0.46189484\n","---------------------------------\n","step:  3000 \n","Hypothesis:  [[0.16272077]\n"," [0.20887567]\n"," [0.69876504]\n"," [0.6284529 ]\n"," [0.8106496 ]\n"," [0.9528054 ]] \n","Correct (Y):  [[0.]\n"," [0.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]] \n","Accuracy:  0.8333333 \n","Cost:  0.3890868\n","---------------------------------\n","step:  4000 \n","Hypothesis:  [[0.12896673]\n"," [0.20683913]\n"," [0.6243662 ]\n"," [0.6559824 ]\n"," [0.83756274]\n"," [0.9553699 ]] \n","Correct (Y):  [[0.]\n"," [0.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]] \n","Accuracy:  0.8333333 \n","Cost:  0.33224702\n","---------------------------------\n","step:  5000 \n","Hypothesis:  [[0.10305277]\n"," [0.20274615]\n"," [0.55730665]\n"," [0.68058664]\n"," [0.86048365]\n"," [0.958927  ]] \n","Correct (Y):  [[0.]\n"," [0.]\n"," [1.]\n"," [1.]\n"," [1.]\n"," [1.]] \n","Accuracy:  0.8333333 \n","Cost:  0.2878699\n","---------------------------------\n","step:  6000 \n","Hypothesis:  [[0.08306794]\n"," [0.19694948]\n"," [0.4993025 ]\n"," [0.7021427 ]\n"," [0.87963927]\n"," [0.96289194]] \n","Correct (Y):  [[0.]\n"," [0.]\n"," [0.]\n"," [1.]\n"," [1.]\n"," [1.]] \n","Accuracy:  1.0 \n","Cost:  0.25291482\n","---------------------------------\n","step:  7000 \n","Hypothesis:  [[0.06764743]\n"," [0.19017716]\n"," [0.44995436]\n"," [0.7209542 ]\n"," [0.8955032 ]\n"," [0.9668098 ]] \n","Correct (Y):  [[0.]\n"," [0.]\n"," [0.]\n"," [1.]\n"," [1.]\n"," [1.]] \n","Accuracy:  1.0 \n","Cost:  0.22500677\n","---------------------------------\n","step:  8000 \n","Hypothesis:  [[0.05569779]\n"," [0.18299724]\n"," [0.40813392]\n"," [0.73741937]\n"," [0.9086269 ]\n"," [0.97044265]] \n","Correct (Y):  [[0.]\n"," [0.]\n"," [0.]\n"," [1.]\n"," [1.]\n"," [1.]] \n","Accuracy:  1.0 \n","Cost:  0.20238648\n","---------------------------------\n","step:  9000 \n","Hypothesis:  [[0.04636656]\n"," [0.1757776 ]\n"," [0.37260923]\n"," [0.751919  ]\n"," [0.91952574]\n"," [0.97370005]] \n","Correct (Y):  [[0.]\n"," [0.]\n"," [0.]\n"," [1.]\n"," [1.]\n"," [1.]] \n","Accuracy:  1.0 \n","Cost:  0.18377542\n","---------------------------------\n","step:  10000 \n","Hypothesis:  [[0.03900886]\n"," [0.16873394]\n"," [0.34226865]\n"," [0.7647782 ]\n"," [0.9286344 ]\n"," [0.97657007]] \n","Correct (Y):  [[0.]\n"," [0.]\n"," [0.]\n"," [1.]\n"," [1.]\n"," [1.]] \n","Accuracy:  1.0 \n","Cost:  0.16824543\n","---------------------------------\n"]}],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","X = np.array([[1, 2], [2, 3], [3, 1],[4, 3], [5, 3], [6, 2]], dtype=np.float32)\n","Y = np.array([[0], [0], [0], [1], [1], [1]], dtype=np.float32)\n","\n","W = tf.Variable(tf.random.normal([2, 1]))\n","b = tf.Variable(tf.random.normal([1]))\n","\n","learning_rate = 0.01\n","\n","def logisticRegression():\n","  with tf.GradientTape() as tape:\n","    hyp = tf.sigmoid(tf.matmul(X, W) + b)\n","    cost = -tf.reduce_mean(Y * tf.math.log(hyp) + (1 - Y) * tf.math.log(1 - hyp))\n","    gradients = tape.gradient(cost, [W, b])\n","\n","    tf.optimizers.SGD(learning_rate).apply_gradients(zip(gradients, [W, b]))\n","\n","\n","for step in range(10001):\n","  logisticRegression()\n","\n","  if step % 1000 == 0:\n","    hyp = tf.sigmoid(tf.matmul(X, W) + b)\n","    cost = -tf.reduce_mean(Y * tf.math.log(hyp) + (1 - Y) * tf.math.log(1 - hyp))\n","    prediction = tf.cast(hyp > 0.5, dtype=tf.float32) # tf.cast(): 0.5보다 작으면 0, 크면 1을 반환\n","\n","    accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, Y), dtype= np.float32))\n","\n","    print(\"step: \", step, \"\\nHypothesis: \", hyp.numpy(), \"\\nCorrect (Y): \",\n","          prediction.numpy(), \"\\nAccuracy: \", accuracy.numpy(), \"\\nCost: \", cost.numpy(), end=\"\\n---------------------------------\\n\")\n"]}]}