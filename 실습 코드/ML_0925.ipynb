{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOkrh4N04CNFJky3SSXw8Gk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"frjmQdKF1yP0","executionInfo":{"status":"ok","timestamp":1696489744251,"user_tz":-540,"elapsed":31442,"user":{"displayName":"김주엽","userId":"12669261044801974628"}},"outputId":"d5a1907f-5fb9-40c0-df4a-e022b64055cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["step :  0 \n","model:  [0 0 1 1 0 1 0 0] \n","accuracy:  0.5 \n","cost:  1.6304662\n","-----------------------------------------------------------------\n","step :  500 \n","model:  [2 2 2 1 0 1 0 0] \n","accuracy:  0.875 \n","cost:  0.46125945\n","-----------------------------------------------------------------\n","step :  1000 \n","model:  [2 2 2 1 0 1 0 0] \n","accuracy:  0.875 \n","cost:  0.30304968\n","-----------------------------------------------------------------\n","step :  1500 \n","model:  [2 2 2 1 1 1 0 0] \n","accuracy:  1.0 \n","cost:  0.24161641\n","-----------------------------------------------------------------\n","step :  2000 \n","model:  [2 2 2 1 1 1 0 0] \n","accuracy:  1.0 \n","cost:  0.20895936\n","-----------------------------------------------------------------\n"]}],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","x_data = np.array([[1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5], [1, 2, 5, 6], [1, 5, 5, 5], [1, 7, 7, 7]], dtype=np.float32)\n","y_data = np.array([[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]], dtype=np.float32)\n","\n","W = tf.Variable(tf.random.normal([4, 3]))\n","b = tf.Variable(tf.random.normal([3]))\n","\n","learning_rate = 0.1\n","\n","def softmax_classfier():\n","  with tf.GradientTape() as tape:\n","    model_LC = tf.matmul(x_data, W) + b\n","    cost = tf.reduce_sum(tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model_LC, labels=y_data)))\n","\n","    gradients = tape.gradient(cost, [W, b])\n","    tf.optimizers.SGD(learning_rate).apply_gradients(zip(gradients, [W, b]))\n","\n","for step in range(2001):\n","  softmax_classfier()\n","\n","  if step % 500 == 0:\n","    model_LC = tf.matmul(x_data, W) + b\n","    model = tf.argmax(tf.nn.softmax(model_LC), 1)\n","    cost = tf.reduce_sum(tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model_LC, labels=y_data)))\n","    accuracy = tf.reduce_mean(tf.cast(tf.equal(model, tf.argmax(y_data, 1)), tf.float32))\n","\n","    print(\"step : \", step, \"\\nmodel: \", model.numpy(), \"\\naccuracy: \", accuracy.numpy(), \"\\ncost: \", cost.numpy(), end=\"\\n-----------------------------------------------------------------\\n\")\n"]}]}