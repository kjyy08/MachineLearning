{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNmdoa3+MzDjXTLvo2tiTv8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TbKHw8uhVKM3"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","\n","x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n","y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n","\n","W = tf.Variable(tf.random.normal([2, 1]))\n","b = tf.Variable(tf.random.normal([1]))\n","learning_rate = 0.1\n","\n","def xor():\n","  with tf.GradientTape() as tape:\n","    model = tf.sigmoid(tf.matmul(x_data ,W) + b)\n","    cost = -tf.reduce_mean(y_data * tf.math.log(model) + (1 - y_data) * tf.math.log(1 - model))\n","    gradients = tape.gradient(cost, [W, b])\n","    tf.optimizers.SGD(learning_rate).apply_gradients(zip(gradients, [W, b]))\n","\n","for step in range(10001):\n","  xor()\n","  model = tf.sigmoid(tf.matmul(x_data, W) + b)\n","  cost = -tf.reduce_mean(y_data * tf.math.log(model) + (1 - y_data) * tf.math.log(1 - model))\n","  prediction = tf.cast(model > 0.5, dtype=tf.float32) # tf.cast(): 0.5보다 작으면 0, 크면 1을 반환\n","  accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, y_data), dtype= np.float32))\n","\n","  if step % 1000 == 0:\n","    print(\"step: \", step, \"\\nAccuracy: \", accuracy.numpy(), \"\\nCost: \", cost.numpy(), end=\"\\n---------------------------------\\n\")\n","\n","\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n","y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n","\n","W1 = tf.Variable(tf.random.normal([2, 2]))\n","b1 = tf.Variable(tf.random.normal([2]))\n","W2 = tf.Variable(tf.random.normal([2, 1]))\n","b2 = tf.Variable(tf.random.normal([1]))\n","learning_rate = 0.1\n","\n","def xor_nn():\n","  with tf.GradientTape() as tape:\n","    layer1 = tf.sigmoid(tf.matmul(x_data, W1) + b1)\n","    model = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n","    cost = -tf.reduce_mean(y_data * tf.math.log(model) + (1 - y_data) * tf.math.log(1 - model))\n","    gradients = tape.gradient(cost, [W2, b2, W1, b1])\n","    tf.optimizers.SGD(learning_rate).apply_gradients(zip(gradients, [W2, b2, W1, b1]))\n","\n","for step in range(10001):\n","  xor_nn()\n","  layer1 = tf.sigmoid(tf.matmul(x_data, W1) + b1)\n","  model = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n","  cost = -tf.reduce_mean(y_data * tf.math.log(model) + (1 - y_data) * tf.math.log(1 - model))\n","  prediction = tf.cast(model > 0.5, dtype=tf.float32) # tf.cast(): 0.5보다 작으면 0, 크면 1을 반환\n","  accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, y_data), dtype= np.float32))\n","\n","  if step % 1000 == 0:\n","    print(\"step: \", step, \"\\nAccuracy: \", accuracy.numpy(), \"\\nCost: \", cost.numpy(), end=\"\\n---------------------------------\\n\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LhmrpzS5ZqMt","executionInfo":{"status":"ok","timestamp":1697442165794,"user_tz":-540,"elapsed":166476,"user":{"displayName":"김주엽","userId":"12669261044801974628"}},"outputId":"c59e00be-e5ae-4b96-d195-db016ef5196a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["step:  0 \n","Accuracy:  0.5 \n","Cost:  0.80552113\n","---------------------------------\n","step:  1000 \n","Accuracy:  0.75 \n","Cost:  0.65050465\n","---------------------------------\n","step:  2000 \n","Accuracy:  0.75 \n","Cost:  0.52287114\n","---------------------------------\n","step:  3000 \n","Accuracy:  1.0 \n","Cost:  0.20099373\n","---------------------------------\n","step:  4000 \n","Accuracy:  1.0 \n","Cost:  0.07826179\n","---------------------------------\n","step:  5000 \n","Accuracy:  1.0 \n","Cost:  0.045596242\n","---------------------------------\n","step:  6000 \n","Accuracy:  1.0 \n","Cost:  0.03166684\n","---------------------------------\n","step:  7000 \n","Accuracy:  1.0 \n","Cost:  0.02410328\n","---------------------------------\n","step:  8000 \n","Accuracy:  1.0 \n","Cost:  0.019393714\n","---------------------------------\n","step:  9000 \n","Accuracy:  1.0 \n","Cost:  0.016193436\n","---------------------------------\n","step:  10000 \n","Accuracy:  1.0 \n","Cost:  0.013883254\n","---------------------------------\n"]}]}]}